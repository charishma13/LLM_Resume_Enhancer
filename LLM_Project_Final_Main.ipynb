{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda119a8",
   "metadata": {},
   "source": [
    "## InstallingLibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53cd854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (0.0.306)\n",
      "Requirement already satisfied: openai in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: pydantic==1.10.12 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (1.10.12)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from pydantic==1.10.12) (4.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (3.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.41)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai 'pydantic==1.10.12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e9ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (3.16.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca88c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e47afed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (0.0.306)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (3.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.41)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788ac0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from accelerate) (0.15.1)\n",
      "Requirement already satisfied: filelock in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2023.4.0)\n",
      "Requirement already satisfied: requests in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a239a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: portalocker in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: regex in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sacrebleu) (2022.7.9)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sacrebleu) (1.24.3)\n",
      "Requirement already satisfied: colorama in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from sacrebleu) (4.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3c84fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (2023.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from evaluate) (0.13.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: six in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from responses<0.19->evaluate) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2e1d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in /Users/pulicharishma/anaconda3/lib/python3.11/site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30859d46",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0319367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python file for manipulation\n",
    "import resume_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61a1f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing connect_llm_model function from resume_llm.py file\n",
    "from resume_llm import connect_llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296608fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61071977",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = connect_llm_model(openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1a4154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.3, model_kwargs={'frequency_penalty': 0.1}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168f626",
   "metadata": {},
   "source": [
    "## Importing the resume and converting into text format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832c2ad",
   "metadata": {},
   "source": [
    "### Document file importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8aef217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495d3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Docx2txtLoader(\"charisjma resume.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "693b0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baa3630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"COVID-19 Certainty Prediction from X-Ray Images using Deep Learning\\n\\nDeveloped a robust Deep Learning model utilizing a Neural Network architecture to predict COVID-19 infection based on chest X-ray images. This project aimed to enhance the accuracy and efficiency of COVID-19 diagnosis through image analysis and machine learning techniques.\\n\\nConducted comprehensive analysis and preprocessing of a diverse dataset consisting of chest X-ray images. This included data augmentation, normalization, and feature extraction to optimize model performance.\\n\\nAchieved remarkable predictive accuracy of 91% in COVID-19 diagnosis, contributing to more reliable and efficient early detection of the virus. The model's performance was rigorously evaluated using appropriate metrics.\\n\\n\\n\\nIMDB sentimental analysis and recommendation sytem (01/2020 - 02/2020)\\n\\nDeveloped a comprehensive IMDb sentiment analysis and genre-based recommendation system with a focus on enhancing user experience and content discovery on the platform. This project combined natural language processing (NLP) and machine learning techniques to provide insightful sentiment analysis and personalized movie recommendations. \\n\\nEngineered a sophisticated recommendation system that leveraged user preferences and movie genres. This system offered personalized movie and TV show recommendations to users based on their viewing history and interests.\\n\\nContinuously optimized recommendation algorithms to ensure high-quality and relevant recommendations, contributing to increased user retention and platform usage.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text = \"\\n\".join([page.page_content for page in pages])\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da528f15",
   "metadata": {},
   "source": [
    "### TextFile importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dafc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"sample.txt\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44af7763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text = \"\\n\".join([page.page_content for page in pages])\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad03be",
   "metadata": {},
   "source": [
    "### Pdf file importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7daf9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"Resume_Charishma.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027ebdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Charishma Puli cpuli1@umbc.edu | +16677703907 Academic Qualification  ——————————————————————— University of Maryland, Baltimore County     Expected: May 2023  Master of Professional Studies in Data Science, GPA: 3.6/4.0 (Till Date)  Related Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management. Jawaharlal Nehru Technological University Hyderabad   Graduated: May 2021 Bachelors of Technology, Computer Science and Engineering, GPA: 8.02/10 Related Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence. Work Experience ———————————————————————Atoms Lab | Research Assistant (UMBC)      (Aug 2023 to Present) •Working on Symbolic Regression Algorithm in Genetic Programming. • Generating computer generated equations for zeolites atoms combinations with other elements. The goal is to predict polyatomic combination equations with zeolites Wipro Technology Limited | Project Engineer ( Data Analyst )         (Aug 2021 to Aug 2022) •Worked on Informatics ETL tool •Trained on Big Data in Hadoop, Apache Spark, Hive, AWS •Data analyst & information management. Verzeo Internship                (Aug 2020 to Oct 2020) •Created Machine Learning models •Used data visualization for the analysis of student behavior algorithms •Used Machine Learning algorithms like linear regression, random forest for analyzing the heart diseases Projects ——————————————————————— Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning ( Mar 2021 to May 2021)•Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays, Every image is consisted to 224,224 pixels.•Used CNN (Convolutional Neural Networks) model RESNET50, which extract each feature from the image. Every feature is ﬂattened and then classifying withe the DENSE layer as FULLY CONNECTED LAYER with SIGMOID activation done. •ResNet50 is a variant of ResNet model which has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer.\\n•The model gives 92 % accuracy. It is able to precisely identify whether the provided x- ray is of Covid symptomatic or not.IMDB sentimental analysis and recommendation system           (Jan 2020 to Feb 2020)•The model predict the sentiment (Positive and Negative) of the input sentence. The model adds with genre based recommendation system at the end.•The neural network is a sequential model, which is Dense layered network with Relu activation function in hidden layer and Sigmoid activation function for the output layer.Classiﬁcation Model that predicts heart disease in a subject          (Sept 2020 to Oct 2020)•Built a classiﬁcation model that predicts heart disease in a subject•By implementing various frameworks such as Keras, TensorFlow, Scikit- Learn, Gradient boosting and used various techniques such as Logistic Regression, Bayesian model, Neural Networks, Random forest, SVM, Decision Tree, KNN. Exploratory Data Analysis that analyze students performance         (Aug 2020 to Sept 2020)•Analysis on understanding how the student’s performance (test scores) is affected by the other variables (Gender, Ethnicity, Parental level of education, Lunch, Test preparation course). Online bus reservation system          (Dec 2019 to Mar 2020)•Project Link:Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system Technical Skills——————————————————————— Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & AlgorithmsData Visualization tools: Tableau, Power BI Web Designing: HTML , CSS , JavaScript Cloud & Database: Oracle, SQL, Apache Spark, Hadoop Achievements——————————————————————— •Secured second Prize in Competitive Programming Workshop, Organised by Coding Club JNTUH-CEH (2020)  •JNTUH QUEST 2020 - Coordinator for \"BLOCKCHAIN Technology\" Workshop (2020) JNTUH QUEST 2019 - Participated in \"DATA SCIENCE & MACHINE LEARNING” Workshop (2018) Participated in Workshop conducted by JNTUH •TEDX - MLRIT (2019) Participated in TED talks conducted by MLRIT •PATH CREATORS, HYDERABAD (2018) Attended Workshop on ROBOTICS and constructed a real time robot'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text = \"\\n\".join([page.page_content for page in pages])\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b9458",
   "metadata": {},
   "source": [
    "## Calling the functions file_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776c7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resume_llm import file_reader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe455037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Charishma Puli cpuli1@umbc.edu | +16677703907 Academic Qualification  ——————————————————————— University of Maryland, Baltimore County     Expected: May 2023  Master of Professional Studies in Data Science, GPA: 3.6/4.0 (Till Date)  Related Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management. Jawaharlal Nehru Technological University Hyderabad   Graduated: May 2021 Bachelors of Technology, Computer Science and Engineering, GPA: 8.02/10 Related Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence. Work Experience ———————————————————————Atoms Lab | Research Assistant (UMBC)      (Aug 2023 to Present) •Working on Symbolic Regression Algorithm in Genetic Programming. • Generating computer generated equations for zeolites atoms combinations with other elements. The goal is to predict polyatomic combination equations with zeolites Wipro Technology Limited | Project Engineer ( Data Analyst )         (Aug 2021 to Aug 2022) •Worked on Informatics ETL tool •Trained on Big Data in Hadoop, Apache Spark, Hive, AWS •Data analyst & information management. Verzeo Internship                (Aug 2020 to Oct 2020) •Created Machine Learning models •Used data visualization for the analysis of student behavior algorithms •Used Machine Learning algorithms like linear regression, random forest for analyzing the heart diseases Projects ——————————————————————— Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning ( Mar 2021 to May 2021)•Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays, Every image is consisted to 224,224 pixels.•Used CNN (Convolutional Neural Networks) model RESNET50, which extract each feature from the image. Every feature is ﬂattened and then classifying withe the DENSE layer as FULLY CONNECTED LAYER with SIGMOID activation done. •ResNet50 is a variant of ResNet model which has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer.\\n•The model gives 92 % accuracy. It is able to precisely identify whether the provided x- ray is of Covid symptomatic or not.IMDB sentimental analysis and recommendation system           (Jan 2020 to Feb 2020)•The model predict the sentiment (Positive and Negative) of the input sentence. The model adds with genre based recommendation system at the end.•The neural network is a sequential model, which is Dense layered network with Relu activation function in hidden layer and Sigmoid activation function for the output layer.Classiﬁcation Model that predicts heart disease in a subject          (Sept 2020 to Oct 2020)•Built a classiﬁcation model that predicts heart disease in a subject•By implementing various frameworks such as Keras, TensorFlow, Scikit- Learn, Gradient boosting and used various techniques such as Logistic Regression, Bayesian model, Neural Networks, Random forest, SVM, Decision Tree, KNN. Exploratory Data Analysis that analyze students performance         (Aug 2020 to Sept 2020)•Analysis on understanding how the student’s performance (test scores) is affected by the other variables (Gender, Ethnicity, Parental level of education, Lunch, Test preparation course). Online bus reservation system          (Dec 2019 to Mar 2020)•Project Link:Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system Technical Skills——————————————————————— Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & AlgorithmsData Visualization tools: Tableau, Power BI Web Designing: HTML , CSS , JavaScript Cloud & Database: Oracle, SQL, Apache Spark, Hadoop Achievements——————————————————————— •Secured second Prize in Competitive Programming Workshop, Organised by Coding Club JNTUH-CEH (2020)  •JNTUH QUEST 2020 - Coordinator for \"BLOCKCHAIN Technology\" Workshop (2020) JNTUH QUEST 2019 - Participated in \"DATA SCIENCE & MACHINE LEARNING” Workshop (2018) Participated in Workshop conducted by JNTUH •TEDX - MLRIT (2019) Participated in TED talks conducted by MLRIT •PATH CREATORS, HYDERABAD (2018) Attended Workshop on ROBOTICS and constructed a real time robot'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume = file_reader(\"Resume_Charishma.pdf\")\n",
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af1912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_reader(\"sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f3124d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"COVID-19 Certainty Prediction from X-Ray Images using Deep Learning\\n\\nDeveloped a robust Deep Learning model utilizing a Neural Network architecture to predict COVID-19 infection based on chest X-ray images. This project aimed to enhance the accuracy and efficiency of COVID-19 diagnosis through image analysis and machine learning techniques.\\n\\nConducted comprehensive analysis and preprocessing of a diverse dataset consisting of chest X-ray images. This included data augmentation, normalization, and feature extraction to optimize model performance.\\n\\nAchieved remarkable predictive accuracy of 91% in COVID-19 diagnosis, contributing to more reliable and efficient early detection of the virus. The model's performance was rigorously evaluated using appropriate metrics.\\n\\n\\n\\nIMDB sentimental analysis and recommendation sytem (01/2020 - 02/2020)\\n\\nDeveloped a comprehensive IMDb sentiment analysis and genre-based recommendation system with a focus on enhancing user experience and content discovery on the platform. This project combined natural language processing (NLP) and machine learning techniques to provide insightful sentiment analysis and personalized movie recommendations. \\n\\nEngineered a sophisticated recommendation system that leveraged user preferences and movie genres. This system offered personalized movie and TV show recommendations to users based on their viewing history and interests.\\n\\nContinuously optimized recommendation algorithms to ensure high-quality and relevant recommendations, contributing to increased user retention and platform usage.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_reader(\"charisjma resume.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a32063",
   "metadata": {},
   "source": [
    "## Inputing job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aa25a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.linkedin.com/jobs/view/3774779142\n",
    "job_posting = \"\"\"\n",
    "Data Engineer\n",
    "Capital One · McLean, VA  4 hours ago  · 14 applicants\n",
    "Full-timeMatches your job preferences, job type is Full-time.  Entry level\n",
    "10,001+ employees · Financial Services\n",
    "32 company alumni work here · 157 school alumni work here\n",
    "See how you compare to 14 applicants. Try Premium for $0\n",
    "Skills: Apache Spark, Big Data, +8 more\n",
    "View verifications related to this job post.View verifications related to this job post.\n",
    "Show all\n",
    "\n",
    "Apply\n",
    "\n",
    "Save\n",
    "Save Data Engineer at Capital One\n",
    "Share\n",
    "Show more options\n",
    "About the job\n",
    "Center 1 (19052), United States of America, McLean, VirginiaData Engineer\n",
    "\n",
    "Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. Capital One’s Finance Tech team is seeking a Senior Associate, Data Engineer who is passionate about marrying data with emerging technologies. As a Capital One Senior Associate, Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\n",
    "\n",
    "What You’ll Do\n",
    "\n",
    " Proactively seeks out opportunities to address customer needs and influences stakeholders so that we are building the best solutions for the most important problems \n",
    " Support the design and development of scalable data architectures and systems that extract, store, and process large amounts of data \n",
    " Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity \n",
    " Collaborate with Data Scientists, Machine Learning Engineers, Business Analysts and/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling \n",
    " Implement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs \n",
    "\n",
    "Basic Qualifications: \n",
    "\n",
    " Bachelor’s Degree \n",
    " At least 2 years of experience in application development (Internship experience does not apply) \n",
    " At least 1 year of experience in big data technologies \n",
    "\n",
    "Preferred Qualifications: \n",
    "\n",
    " 3+ years of experience developing data pipelines using Python or Scala \n",
    " 2+ years of experience with distributed computing tools (Spark, EMR, Hadoop) \n",
    " 2+ years of experience with UNIX/Linux including basic commands and shell scripting \n",
    " 1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) \n",
    " 1+ years of data warehousing experience (Redshift or Snowflake) \n",
    " 1+ years of experience with Agile engineering practices \n",
    "\n",
    "At this time, Capital One will not sponsor a new applicant for employment authorization for this position.\n",
    "\n",
    "Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n",
    "\n",
    "This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n",
    "\n",
    "If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n",
    "\n",
    "For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n",
    "\n",
    "Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n",
    "\n",
    "Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3e011",
   "metadata": {},
   "source": [
    "## Extracting Resume skills Using Pydantic parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa656015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/modules/model_io/output_parsers/\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from resume_llm import Resume_Skills\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Resume_Skills)\n",
    "\n",
    "SystemMessege = \"Extract the information and get the specified skills only mentioned in the resume\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(template = 'Using format {format_instructions} and resume {resume} to get the itemised list')\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [SystemMessege, human_message_prompt]\n",
    "    )\n",
    "output = model(\n",
    "        chat_prompt.format_prompt(resume=resume,format_instructions = parser.get_format_instructions()).to_messages()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88db5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"technical_skills\": [\n",
      "    \"Python\",\n",
      "    \"MS Office\",\n",
      "    \"C\",\n",
      "    \"Data Structures and Algorithms\",\n",
      "    \"Statistics & Probability\",\n",
      "    \"Operating Systems\",\n",
      "    \"Compiler Design\",\n",
      "    \"Computer Networks\",\n",
      "    \"Cloud Computing\",\n",
      "    \"Database management systems\",\n",
      "    \"Machine Learning\",\n",
      "    \"Artificial Intelligence\",\n",
      "    \"Tableau\",\n",
      "    \"Power BI\",\n",
      "    \"HTML\",\n",
      "    \"CSS\",\n",
      "    \"JavaScript\",\n",
      "    \"Oracle\",\n",
      "    \"SQL\",\n",
      "    \"Apache Spark\",\n",
      "    \"Hadoop\"\n",
      "  ],\n",
      "  \"non_technical_skills\": [\n",
      "    \"Leadership in Management\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92b1dc",
   "metadata": {},
   "source": [
    "## Extracting Job skills using pydatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c4708a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using resume.pdf\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from resume_llm import Job_Skills\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Job_Skills)\n",
    "\n",
    "SystemMessege = \"Extract and mine the information provided and give directly the list of all the specified skills mentioned in the job posting\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(template = 'Using format {format_instructions} and job posting {job_posting} to get the itemised list')\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [SystemMessege, human_message_prompt]\n",
    "    )\n",
    "output = model(\n",
    "        chat_prompt.format_prompt(job_posting=job_posting,format_instructions = parser.get_format_instructions()).to_messages()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65d0c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"technical_skills\": [\n",
      "    \"Apache Spark\",\n",
      "    \"Big Data\",\n",
      "    \"Python\",\n",
      "    \"Scala\",\n",
      "    \"EMR\",\n",
      "    \"Hadoop\",\n",
      "    \"UNIX/Linux\",\n",
      "    \"AWS\",\n",
      "    \"Microsoft Azure\",\n",
      "    \"Google Cloud\",\n",
      "    \"Redshift\",\n",
      "    \"Snowflake\"\n",
      "  ],\n",
      "  \"non_technical_skills\": [\n",
      "    \"Agile engineering practices\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14c15a",
   "metadata": {},
   "source": [
    "## Extracting valuable information from the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd7a0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using resume.pdf\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from resume_llm import Job_Description\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=resume_llm.Job_Description)\n",
    "\n",
    "SystemMessege = \"Extract and mine the information provided in the job posting\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(template = 'Using format {format_instructions} and job posting {job_posting} to get the itemised list')\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [SystemMessege, human_message_prompt]\n",
    "    )\n",
    "output = model(\n",
    "        chat_prompt.format_prompt(job_posting=job_posting,format_instructions = parser.get_format_instructions()).to_messages()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19bee99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company\": \"Capital One\",\n",
      "  \"job_title\": \"Data Engineer\",\n",
      "  \"team\": null,\n",
      "  \"job_summary\": \"Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. Capital One’s Finance Tech team is seeking a Senior Associate, Data Engineer who is passionate about marrying data with emerging technologies. As a Capital One Senior Associate, Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\",\n",
      "  \"salary\": null,\n",
      "  \"duties\": [\n",
      "    \"Proactively seeks out opportunities to address customer needs and influences stakeholders so that we are building the best solutions for the most important problems\",\n",
      "    \"Support the design and development of scalable data architectures and systems that extract, store, and process large amounts of data\",\n",
      "    \"Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity\",\n",
      "    \"Collaborate with Data Scientists, Machine Learning Engineers, Business Analysts and/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling\",\n",
      "    \"Implement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs\"\n",
      "  ],\n",
      "  \"qualifications\": [\n",
      "    \"Bachelor’s Degree\",\n",
      "    \"At least 2 years of experience in application development (Internship experience does not apply)\",\n",
      "    \"At least 1 year of experience in big data technologies\",\n",
      "    \"3+ years of experience developing data pipelines using Python or Scala\",\n",
      "    \"2+ years of experience with distributed computing tools (Spark, EMR, Hadoop)\",\n",
      "    \"2+ years of experience with UNIX/Linux including basic commands and shell scripting\",\n",
      "    \"1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\",\n",
      "    \"1+ years of data warehousing experience (Redshift or Snowflake)\",\n",
      "    \"1+ years of experience with Agile engineering practices\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ec4725f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'Capital One',\n",
       " 'job_title': 'Data Engineer',\n",
       " 'team': None,\n",
       " 'job_summary': \"Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. Capital One’s Finance Tech team is seeking a Senior Associate, Data Engineer who is passionate about marrying data with emerging technologies. As a Capital One Senior Associate, Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\",\n",
       " 'salary': None,\n",
       " 'duties': ['Proactively seeks out opportunities to address customer needs and influences stakeholders so that we are building the best solutions for the most important problems',\n",
       "  'Support the design and development of scalable data architectures and systems that extract, store, and process large amounts of data',\n",
       "  'Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity',\n",
       "  'Collaborate with Data Scientists, Machine Learning Engineers, Business Analysts and/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling',\n",
       "  'Implement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs'],\n",
       " 'qualifications': ['Bachelor’s Degree',\n",
       "  'At least 2 years of experience in application development (Internship experience does not apply)',\n",
       "  'At least 1 year of experience in big data technologies',\n",
       "  '3+ years of experience developing data pipelines using Python or Scala',\n",
       "  '2+ years of experience with distributed computing tools (Spark, EMR, Hadoop)',\n",
       "  '2+ years of experience with UNIX/Linux including basic commands and shell scripting',\n",
       "  '1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)',\n",
       "  '1+ years of data warehousing experience (Redshift or Snowflake)',\n",
       "  '1+ years of experience with Agile engineering practices']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "job_data_dict = json.loads(output.content)\n",
    "job_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "601cca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proactively seeks out opportunities to address customer needs and influences stakeholders so that we are building the best solutions for the most important problems',\n",
       " 'Support the design and development of scalable data architectures and systems that extract, store, and process large amounts of data',\n",
       " 'Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity',\n",
       " 'Collaborate with Data Scientists, Machine Learning Engineers, Business Analysts and/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling',\n",
       " 'Implement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duties = job_data_dict['duties']\n",
    "duties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34bee3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bachelor’s Degree',\n",
       " 'At least 2 years of experience in application development (Internship experience does not apply)',\n",
       " 'At least 1 year of experience in big data technologies',\n",
       " '3+ years of experience developing data pipelines using Python or Scala',\n",
       " '2+ years of experience with distributed computing tools (Spark, EMR, Hadoop)',\n",
       " '2+ years of experience with UNIX/Linux including basic commands and shell scripting',\n",
       " '1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)',\n",
       " '1+ years of data warehousing experience (Redshift or Snowflake)',\n",
       " '1+ years of experience with Agile engineering practices']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifications = job_data_dict['qualifications']\n",
    "qualifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca703151",
   "metadata": {},
   "source": [
    "## Zeroshot prompting using the langchain modules Schema, prompts using whole job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d8146d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate,SystemMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9c750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"Improvements\", description=\"improvements for the resume\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07b74d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Get the resume improvements with the job_posting in the questions and with format provided:\\n{format_instructions}\\nresume:{resume}\\njob_posting:{job_posting}\",\n",
    "    input_variables=[\"resume\",\"job_posting\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15df7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making HumanMessagePromptTemplate\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78fba355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['job_posting', 'resume', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['resume', 'job_posting'], partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"Improvements\": string  // improvements for the resume\\n}\\n```'}, template='Get the resume improvements with the job_posting in the questions and with format provided:\\n{format_instructions}\\nresume:{resume}\\njob_posting:{job_posting}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ChatPromptTemplate: Combine System + Human\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5f9dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_with_values = chat_prompt.format_prompt(resume=resume, \\\n",
    "                                                   job_posting=job_posting, \\\n",
    "                                                   text=\"Provide the resume improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56e3c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model(chat_prompt_with_values.to_messages()).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f816d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.replace('```json\\n','')\n",
    "Improvements_job_postings = response.replace('\\n```','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241d7b7",
   "metadata": {},
   "source": [
    "## Hard prompting using the langchain modules Schema, prompts with valueable information in job posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d65b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Get the resume improvements with the duties {duties}, qualifications {qualifications}. Check if the user is matching the qualifications, suggest the improvements need to be done and with format provided:\\n{format_instructions}\\nresume:{resume}\",\n",
    "    input_variables=[\"resume\",\"duties\",'qualifications'],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "676e68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make HumanMessagePromptTemplate\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e1f8736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['duties', 'qualifications', 'resume', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['resume', 'duties', 'qualifications'], partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"Improvements\": string  // improvements for the resume\\n}\\n```'}, template='Get the resume improvements with the duties {duties}, qualifications {qualifications}. Check if the user is matching the qualifications, suggest the improvements need to be done and with format provided:\\n{format_instructions}\\nresume:{resume}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ChatPromptTemplate: Combine System + Human\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17d9c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_imputs = dict(\n",
    "    duties = '\\n    - '.join(job_data_dict['duties']),\n",
    "    qualifications = '\\n    - '.join(job_data_dict['qualifications']),\n",
    "    resume = resume,\n",
    "    text=\"Provide the resume improvements\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a39dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_with_values = chat_prompt.format_prompt(**prompt_imputs)\n",
    "\n",
    "## chat_prompt_with_values.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e40441da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model(chat_prompt_with_values.to_messages()).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01bf6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.replace('```json\\n','')\n",
    "Improvements_duties_qualifications = response.replace('\\n```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "034d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Improvements_duties_qualifications = json.loads(Improvements_duties_qualifications)\n",
    "Improvements = Improvements_duties_qualifications['Improvements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f28492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Add a summary or objective statement at the beginning of the resume to provide a brief overview of your skills and career goals.\\n2. Include specific achievements and quantifiable results in your work experience section to demonstrate your impact and contributions.\\n3. Use bullet points to highlight your responsibilities and accomplishments in each job or project.\\n4. Organize your projects section by listing them in reverse chronological order, starting with the most recent.\\n5. Provide more details about your projects, including the tools and techniques used, the challenges faced, and the outcomes achieved.\\n6. Expand on your technical skills section by providing more specific information about your proficiency level and any relevant certifications or training.\\n7. Consider adding a section for relevant coursework or academic projects to showcase your knowledge and skills in data science.\\n8. Include any relevant professional affiliations, such as memberships in data science organizations or participation in industry conferences.\\n9. Proofread your resume for any grammatical or spelling errors, and ensure consistent formatting throughout.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191fc19",
   "metadata": {},
   "source": [
    "ref: https://www.promptingguide.ai/techniques/graph\n",
    "\n",
    "Will be using these 2 improvements to imrpove the resume using 3 techniques\n",
    "\n",
    "1. Hard Prompts\n",
    "    1. Zero shot prompt\n",
    "    2. Few shot prompt\n",
    "2. COT(Chain of Thoughts) with Self-Ask Prompting or Self Consistency\n",
    "3. COT(Chain of Thoughts) with step by step\n",
    "5. Instructions Prompting\n",
    "\n",
    "Future: Automated Prompt Engineering (APE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bad03afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Evaluation_Scores = pd.DataFrame(index=['Sari', 'hallucination'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbeb7f8",
   "metadata": {},
   "source": [
    "## Zero shot prompting using pydantic parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d410532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resume_llm import Resume_Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "968f74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=resume_llm.Resume_Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5776915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Format of resume\", \"properties\": {\"Basics\": {\"title\": \"Basics\", \"description\": \" The basics of  the for given user resume input.\", \"type\": \"string\"}, \"Introduction\": {\"title\": \"Introduction\", \"description\": \" write only 1 line introduction for the introduction section for given user resume input.\", \"type\": \"string\"}, \"Work_Experiences\": {\"title\": \"Work Experiences\", \"description\": \" The experiece of the candidates with job, duration and description of work done like xyz company from 09-2022 to 08-2023 performed work on spark and databases\", \"type\": \"string\"}, \"Education\": {\"title\": \"Education\", \"description\": \" The education of the candidates with university, duration and description of work done like xyx university from 08-2013 to 07-2018 studied this courses\", \"type\": \"string\"}, \"Awards\": {\"title\": \"Awards\", \"description\": \" The awards are the achievments and honours of the candidates. If the resume don\\'t have the award no need to add this to resume\", \"type\": \"string\"}, \"Projects\": {\"title\": \"Projects\", \"description\": \" The projects section of contains the project, duration and roles and responsibilities of the candidate like xyz project from 05-2019 to 04-2020 worked on backend etc\", \"type\": \"string\"}, \"Skills\": {\"title\": \"Skills\", \"description\": \" An itemized list of technical skills and non-technical Soft skills of the user\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"Basics\", \"Introduction\", \"Work_Experiences\", \"Education\", \"Awards\", \"Projects\", \"Skills\"]}\\n```'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43f7fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero_Shot_Output = model.predict(\"Genetere a resume using the resume:\"+resume+\"with the job posting\"+job_posting+\"in the template\"+parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "828f8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Basics\": \"Charishma Puli cpuli1@umbc.edu | +16677703907\",\n",
      "  \"Introduction\": \"Master of Professional Studies in Data Science with a GPA of 3.6/4.0 and Bachelors of Technology in Computer Science and Engineering with a GPA of 8.02/10\",\n",
      "  \"Work_Experiences\": \"Atoms Lab | Research Assistant (UMBC) (Aug 2023 to Present)\\n- Working on Symbolic Regression Algorithm in Genetic Programming.\\n- Generating computer generated equations for zeolites atoms combinations with other elements. The goal is to predict polyatomic combination equations with zeolites.\\n\\nWipro Technology Limited | Project Engineer (Data Analyst) (Aug 2021 to Aug 2022)\\n- Worked on Informatics ETL tool.\\n- Trained on Big Data in Hadoop, Apache Spark, Hive, AWS.\\n- Data analyst & information management.\\n\\nVerzeo Internship (Aug 2020 to Oct 2020)\\n- Created Machine Learning models.\\n- Used data visualization for the analysis of student behavior algorithms.\\n- Used Machine Learning algorithms like linear regression, random forest for analyzing heart diseases.\",\n",
      "  \"Education\": \"University of Maryland, Baltimore County\\n- Master of Professional Studies in Data Science, Expected: May 2023\\n\\nJawaharlal Nehru Technological University Hyderabad\\n- Bachelors of Technology, Computer Science and Engineering, Graduated: May 2021\",\n",
      "  \"Awards\": \"\",\n",
      "  \"Projects\": \"Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning (Mar 2021 to May 2021)\\n- Built a Deep Learning model using Convolutional Neural Network to predict covid-19 with chest X-rays.\\n\\nIMDB sentimental analysis and recommendation system (Jan 2020 to Feb 2020)\\n- Predicted the sentiment (Positive and Negative) of input sentences.\\n\\nClassification Model that predicts heart disease in a subject (Sept 2020 to Oct 2020)\\n- Built a classification model to predict heart disease using various frameworks and techniques.\\n\\nExploratory Data Analysis that analyze students performance (Aug 2020 to Sept 2020)\\n- Analyzed how student's performance is affected by other variables.\\n\\nOnline bus reservation system (Dec 2019 to Mar 2020)\",\n",
      "  \"Skills\": [\n",
      "    \"Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & Algorithms\",\n",
      "    \"Data Visualization tools: Tableau, Power BI\",\n",
      "    \"Web Designing: HTML, CSS, JavaScript\",\n",
      "    \"Cloud & Database: Oracle, SQL, Apache Spark, Hadoop\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(Zero_Shot_Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c5d93",
   "metadata": {},
   "source": [
    "### Sari Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e0f32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/spaces/evaluate-metric/sari\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "sari = load(\"sari\")\n",
    "sources=[resume]\n",
    "predictions=[Zero_Shot_Output]\n",
    "references=[[job_posting]]\n",
    "sari_score = sari.compute(sources=sources, predictions=predictions, references=references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4f64bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.92408455076582"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sari_score['sari']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dcf494",
   "metadata": {},
   "source": [
    "### hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba37d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "hallucination_model = CrossEncoder('vectara/hallucination_evaluation_model')\n",
    "score = hallucination_model.predict([\n",
    "    [resume, Zero_Shot_Output],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1674daf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5123648], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a356008",
   "metadata": {},
   "source": [
    "Adding Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2420e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Scores['Zero_Shot_Prompting'] = [sari_score['sari'],score[0]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22ebfb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero_Shot_Prompting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sari</th>\n",
       "      <td>34.924085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucination</th>\n",
       "      <td>51.236480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Zero_Shot_Prompting\n",
       "Sari                     34.924085\n",
       "hallucination            51.236480"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be763d9f",
   "metadata": {},
   "source": [
    "If you want to have your response more standardiesd, zeroshot may not work all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddd797",
   "metadata": {},
   "source": [
    "## Forming a resume using COT(Chain of thoughts), using step - by - step approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "442ee6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"basics\", description=\"The basics of the given user's resume input.\"),\n",
    "    ResponseSchema(name=\"introduction\", description=\"Write only 1 line introduction for the introduction section for given user resume input.\"),\n",
    "    ResponseSchema(name=\"work_experiences\", description=\"The experience of the candidates with job, duration, and description of work done like XYZ company from 09-2022 to 08-2023, performed work on Spark and databases.\"),\n",
    "    ResponseSchema(name=\"education\", description=\"The education of the candidates with university, duration, and description of work done like XYZ university from 08-2013 to 07-2018, studied these courses.\"),\n",
    "    ResponseSchema(name=\"awards\", description=\"The awards are the achievements and honors of the candidates. If the resume doesn't have the award, no need to add this to the resume.\"),\n",
    "    ResponseSchema(name=\"projects\", description=\"The projects section contains the project, duration, and roles and responsibilities of the candidate like XYZ project from 05-2019 to 04-2020, worked on the backend, etc.\"),\n",
    "    ResponseSchema(name=\"skills\", description=\"An itemized list of technical skills and non-technical soft skills of the user.\"),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2335daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You're a skilled Resume Writer with a talent for providing resume from the list of suggestions with no extra information. Your process is precise and methodically follows the given steps and provide a resume with this format {format_instructions}\\n {resume} \\n{Improvements}\",\n",
    "    input_variables=['resume','Improvements'],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d295b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "# Prompt includes\n",
    "# - Steps for LLM to follow\n",
    "# - Separator tokens, like <> and backticks for delineating steps and inputs\n",
    "\n",
    "prompt_msgs = [\n",
    "    system_message_prompt,\n",
    "    HumanMessage(\n",
    "        content=(\n",
    "            \"Your objective is to thoroughly analyze both a improvements and my resume, pinpoint the requirements outlined in the job posting that are absent in my resume, and form a resume with the format\" \n",
    "        )\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=(\n",
    "            \"\\nSteps to follow:\"\n",
    "            \"\\nStep 1: Get the Resume for the editing from system_message\"\n",
    "            \"\\nStep 2: Get the Suggested Improvements for the editing from system_message\"\n",
    "            \"\\nStep 3: You must create an resume with those Suggestions which is from the Suggested Improvements from Step 2 that are NOT present in the Resume from Step 1. Follow these sub-steps:\"\n",
    "            \"\\n   Sub-Step 3a: The Basics information of the resume holder should be same\"\n",
    "            \"\"\"\\n   Sub-Step 3b: To add the resume information, For each missing requirement that you identified in Sub-Step 3a, check again whether that requirement is in fact present in my Resume. \n",
    "            Note that a requirement may be present in the Resume in a different phrasing than in the job posting. If the requirement is present in the Resume, remove it from your list of missing requirements.\"\"\"\n",
    "            \"\\n   Sub-Step 3c: Education, work experience and all the factual data remain the same, enhance the descriptions the most\"\n",
    "            \"\\nStep 4: You must finally create a resume for improving my Resume based on the list of missing requirements provided.\"\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    HumanMessage(\n",
    "        content=\"You must now think step - by - step and form a resume for step 4 using some rules to form resume in format given\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Notes: Make sure to answer in the correct format, and stick to any word or item limits.\"\n",
    "    ),\n",
    "]\n",
    "improver_prompt = ChatPromptTemplate(messages=prompt_msgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad9c0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_imputs = dict(\n",
    "    Improvements = Improvements,\n",
    "    resume = resume\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8734d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You're a skilled Resume Writer with a talent for providing resume from the list of suggestions with no extra information. Your process is precise and methodically follows the given steps and provide a resume with this format The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"basics\": string  // The basics of the given user's resume input.\n",
      "\t\"introduction\": string  // Write only 1 line introduction for the introduction section for given user resume input.\n",
      "\t\"work_experiences\": string  // The experience of the candidates with job, duration, and description of work done like XYZ company from 09-2022 to 08-2023, performed work on Spark and databases.\n",
      "\t\"education\": string  // The education of the candidates with university, duration, and description of work done like XYZ university from 08-2013 to 07-2018, studied these courses.\n",
      "\t\"awards\": string  // The awards are the achievements and honors of the candidates. If the resume doesn't have the award, no need to add this to the resume.\n",
      "\t\"projects\": string  // The projects section contains the project, duration, and roles and responsibilities of the candidate like XYZ project from 05-2019 to 04-2020, worked on the backend, etc.\n",
      "\t\"skills\": string  // An itemized list of technical skills and non-technical soft skills of the user.\n",
      "}\n",
      "```\n",
      " Charishma Puli cpuli1@umbc.edu | +16677703907 Academic Qualification  ——————————————————————— University of Maryland, Baltimore County     Expected: May 2023  Master of Professional Studies in Data Science, GPA: 3.6/4.0 (Till Date)  Related Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management. Jawaharlal Nehru Technological University Hyderabad   Graduated: May 2021 Bachelors of Technology, Computer Science and Engineering, GPA: 8.02/10 Related Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence. Work Experience ———————————————————————Atoms Lab | Research Assistant (UMBC)      (Aug 2023 to Present) •Working on Symbolic Regression Algorithm in Genetic Programming. • Generating computer generated equations for zeolites atoms combinations with other elements. The goal is to predict polyatomic combination equations with zeolites Wipro Technology Limited | Project Engineer ( Data Analyst )         (Aug 2021 to Aug 2022) •Worked on Informatics ETL tool •Trained on Big Data in Hadoop, Apache Spark, Hive, AWS •Data analyst & information management. Verzeo Internship                (Aug 2020 to Oct 2020) •Created Machine Learning models •Used data visualization for the analysis of student behavior algorithms •Used Machine Learning algorithms like linear regression, random forest for analyzing the heart diseases Projects ——————————————————————— Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning ( Mar 2021 to May 2021)•Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays, Every image is consisted to 224,224 pixels.•Used CNN (Convolutional Neural Networks) model RESNET50, which extract each feature from the image. Every feature is ﬂattened and then classifying withe the DENSE layer as FULLY CONNECTED LAYER with SIGMOID activation done. •ResNet50 is a variant of ResNet model which has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer.\n",
      "•The model gives 92 % accuracy. It is able to precisely identify whether the provided x- ray is of Covid symptomatic or not.IMDB sentimental analysis and recommendation system           (Jan 2020 to Feb 2020)•The model predict the sentiment (Positive and Negative) of the input sentence. The model adds with genre based recommendation system at the end.•The neural network is a sequential model, which is Dense layered network with Relu activation function in hidden layer and Sigmoid activation function for the output layer.Classiﬁcation Model that predicts heart disease in a subject          (Sept 2020 to Oct 2020)•Built a classiﬁcation model that predicts heart disease in a subject•By implementing various frameworks such as Keras, TensorFlow, Scikit- Learn, Gradient boosting and used various techniques such as Logistic Regression, Bayesian model, Neural Networks, Random forest, SVM, Decision Tree, KNN. Exploratory Data Analysis that analyze students performance         (Aug 2020 to Sept 2020)•Analysis on understanding how the student’s performance (test scores) is affected by the other variables (Gender, Ethnicity, Parental level of education, Lunch, Test preparation course). Online bus reservation system          (Dec 2019 to Mar 2020)•Project Link:Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system Technical Skills——————————————————————— Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & AlgorithmsData Visualization tools: Tableau, Power BI Web Designing: HTML , CSS , JavaScript Cloud & Database: Oracle, SQL, Apache Spark, Hadoop Achievements——————————————————————— •Secured second Prize in Competitive Programming Workshop, Organised by Coding Club JNTUH-CEH (2020)  •JNTUH QUEST 2020 - Coordinator for \"BLOCKCHAIN Technology\" Workshop (2020) JNTUH QUEST 2019 - Participated in \"DATA SCIENCE & MACHINE LEARNING” Workshop (2018) Participated in Workshop conducted by JNTUH •TEDX - MLRIT (2019) Participated in TED talks conducted by MLRIT •PATH CREATORS, HYDERABAD (2018) Attended Workshop on ROBOTICS and constructed a real time robot \n",
      "1. Add a summary or objective statement at the beginning of the resume to provide a brief overview of your skills and career goals.\n",
      "2. Include specific achievements and quantifiable results in your work experience section to demonstrate your impact and contributions.\n",
      "3. Use bullet points to highlight your responsibilities and accomplishments in each job or project.\n",
      "4. Organize your projects section by listing them in reverse chronological order, starting with the most recent.\n",
      "5. Provide more details about your projects, including the tools and techniques used, the challenges faced, and the outcomes achieved.\n",
      "6. Expand on your technical skills section by providing more specific information about your proficiency level and any relevant certifications or training.\n",
      "7. Consider adding a section for relevant coursework or academic projects to showcase your knowledge and skills in data science.\n",
      "8. Include any relevant professional affiliations, such as memberships in data science organizations or participation in industry conferences.\n",
      "9. Proofread your resume for any grammatical or spelling errors, and ensure consistent formatting throughout.\n",
      "Human: Your objective is to thoroughly analyze both a improvements and my resume, pinpoint the requirements outlined in the job posting that are absent in my resume, and form a resume with the format\n",
      "Human: \n",
      "Steps to follow:\n",
      "Step 1: Get the Resume for the editing from system_message\n",
      "Step 2: Get the Suggested Improvements for the editing from system_message\n",
      "Step 3: You must create an resume with those Suggestions which is from the Suggested Improvements from Step 2 that are NOT present in the Resume from Step 1. Follow these sub-steps:\n",
      "   Sub-Step 3a: The Basics information of the resume holder should be same\n",
      "   Sub-Step 3b: To add the resume information, For each missing requirement that you identified in Sub-Step 3a, check again whether that requirement is in fact present in my Resume. \n",
      "            Note that a requirement may be present in the Resume in a different phrasing than in the job posting. If the requirement is present in the Resume, remove it from your list of missing requirements.\n",
      "   Sub-Step 3c: Education, work experience and all the factual data remain the same, enhance the descriptions the most\n",
      "Step 4: You must finally create a resume for improving my Resume based on the list of missing requirements provided.\n",
      "Human: You must now think step - by - step and form a resume for step 4 using some rules to form resume in format given\n",
      "Human: Notes: Make sure to answer in the correct format, and stick to any word or item limits.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "better_improver_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=improver_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "better_improver_chain_response = better_improver_chain.predict(**prompt_imputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d079db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\\t\"basics\": \"Charishma Puli cpuli1@umbc.edu | +16677703907\",\\n\\t\"introduction\": \"Data Science professional with a strong background in computer science and engineering, seeking opportunities to apply my skills and knowledge in a challenging role.\",\\n\\t\"work_experiences\": \"Atoms Lab | Research Assistant (UMBC) (Aug 2023 to Present)\\\\n• Working on Symbolic Regression Algorithm in Genetic Programming.\\\\n• Generating computer-generated equations for zeolite atom combinations with other elements.\\\\n\\\\nWipro Technology Limited | Project Engineer (Data Analyst) (Aug 2021 to Aug 2022)\\\\n• Worked on Informatics ETL tool.\\\\n• Trained on Big Data in Hadoop, Apache Spark, Hive, AWS.\\\\n\\\\nVerzeo Internship (Aug 2020 to Oct 2020)\\\\n• Created Machine Learning models.\\\\n• Used data visualization for the analysis of student behavior algorithms.\\\\n• Used Machine Learning algorithms like linear regression, random forest for analyzing heart diseases.\",\\n\\t\"education\": \"University of Maryland, Baltimore County | Expected: May 2023\\\\nMaster of Professional Studies in Data Science, GPA: 3.6/4.0\\\\nRelated Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management.\\\\n\\\\nJawaharlal Nehru Technological University Hyderabad | Graduated: May 2021\\\\nBachelors of Technology, Computer Science and Engineering, GPA: 8.02/10\\\\nRelated Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence.\",\\n\\t\"awards\": \"\",\\n\\t\"projects\": \"Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning (Mar 2021 to May 2021)\\\\n• Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays.\\\\n\\\\nIMDB sentimental analysis and recommendation system (Jan 2020 to Feb 2020)\\\\n• The model predicts the sentiment (Positive and Negative) of the input sentence.\\\\n\\\\nClassiﬁcation Model that predicts heart disease in a subject (Sept 2020 to Oct 2020)\\\\n• Built a classiﬁcation model that predicts heart disease in a subject.\\\\n\\\\nExploratory Data Analysis that analyze students performance (Aug 2020 to Sept 2020)\\\\n• Analysis on understanding how the student’s performance (test scores) is affected by other variables.\\\\n\\\\nOnline bus reservation system (Dec 2019 to Mar 2020)\\\\n• Project Link: Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system\",\\n\\t\"skills\": \"Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & Algorithms\\\\nData Visualization tools: Tableau, Power BI\\\\nWeb Designing: HTML, CSS, JavaScript\\\\nCloud & Database: Oracle, SQL, Apache Spark, Hadoop\"\\n}'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_improver_chain_response = better_improver_chain_response.replace('```json\\n','')\n",
    "Pred_COT_step_by_step = better_improver_chain_response.replace('\\n```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eeb961f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"basics\": \"Charishma Puli cpuli1@umbc.edu | +16677703907\",\n",
      "\t\"introduction\": \"Data Science professional with a strong background in computer science and engineering, seeking opportunities to apply my skills and knowledge in a challenging role.\",\n",
      "\t\"work_experiences\": \"Atoms Lab | Research Assistant (UMBC) (Aug 2023 to Present)\\n• Working on Symbolic Regression Algorithm in Genetic Programming.\\n• Generating computer-generated equations for zeolite atom combinations with other elements.\\n\\nWipro Technology Limited | Project Engineer (Data Analyst) (Aug 2021 to Aug 2022)\\n• Worked on Informatics ETL tool.\\n• Trained on Big Data in Hadoop, Apache Spark, Hive, AWS.\\n\\nVerzeo Internship (Aug 2020 to Oct 2020)\\n• Created Machine Learning models.\\n• Used data visualization for the analysis of student behavior algorithms.\\n• Used Machine Learning algorithms like linear regression, random forest for analyzing heart diseases.\",\n",
      "\t\"education\": \"University of Maryland, Baltimore County | Expected: May 2023\\nMaster of Professional Studies in Data Science, GPA: 3.6/4.0\\nRelated Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management.\\n\\nJawaharlal Nehru Technological University Hyderabad | Graduated: May 2021\\nBachelors of Technology, Computer Science and Engineering, GPA: 8.02/10\\nRelated Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence.\",\n",
      "\t\"awards\": \"\",\n",
      "\t\"projects\": \"Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning (Mar 2021 to May 2021)\\n• Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays.\\n\\nIMDB sentimental analysis and recommendation system (Jan 2020 to Feb 2020)\\n• The model predicts the sentiment (Positive and Negative) of the input sentence.\\n\\nClassiﬁcation Model that predicts heart disease in a subject (Sept 2020 to Oct 2020)\\n• Built a classiﬁcation model that predicts heart disease in a subject.\\n\\nExploratory Data Analysis that analyze students performance (Aug 2020 to Sept 2020)\\n• Analysis on understanding how the student’s performance (test scores) is affected by other variables.\\n\\nOnline bus reservation system (Dec 2019 to Mar 2020)\\n• Project Link: Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system\",\n",
      "\t\"skills\": \"Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & Algorithms\\nData Visualization tools: Tableau, Power BI\\nWeb Designing: HTML, CSS, JavaScript\\nCloud & Database: Oracle, SQL, Apache Spark, Hadoop\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(Pred_COT_step_by_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0da7a9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4b11",
   "metadata": {},
   "source": [
    "### Sari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75d6513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/spaces/evaluate-metric/sari\n",
    "\n",
    "from evaluate import load\n",
    "sari = load(\"sari\")\n",
    "sources=[resume]\n",
    "predictions=[Pred_COT_step_by_step]\n",
    "references=[[job_posting]]\n",
    "sari_score = sari.compute(sources=sources, predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b1a3d1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sari': 35.62413448166928}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sari_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c4165",
   "metadata": {},
   "source": [
    "## hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22a6d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "hallucination_model = CrossEncoder('vectara/hallucination_evaluation_model')\n",
    "score = hallucination_model.predict([\n",
    "    [resume, Pred_COT_step_by_step],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e309b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8617422], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c7f1a",
   "metadata": {},
   "source": [
    "### Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6aeef810",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Scores['Chain_Of_Thoughts_Step_by_Step'] = [sari_score['sari'],score[0]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dad16b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero_Shot_Prompting</th>\n",
       "      <th>Chain_Of_Thoughts_Step_by_Step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sari</th>\n",
       "      <td>34.924085</td>\n",
       "      <td>35.624134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucination</th>\n",
       "      <td>51.236480</td>\n",
       "      <td>86.174220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Zero_Shot_Prompting  Chain_Of_Thoughts_Step_by_Step\n",
       "Sari                     34.924085                       35.624134\n",
       "hallucination            51.236480                       86.174220"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12764b",
   "metadata": {},
   "source": [
    "## Forming a resume using COT(Chain of thoughts), with self suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e32db4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"basics\", description=\"The basics of the given user's resume input.\"),\n",
    "    ResponseSchema(name=\"introduction\", description=\"Write only 1 line introduction for the introduction section for given user resume input.\"),\n",
    "    ResponseSchema(name=\"work_experiences\", description=\"The experience of the candidates with job, duration, and description of work done like XYZ company from 09-2022 to 08-2023, performed work on Spark and databases.\"),\n",
    "    ResponseSchema(name=\"education\", description=\"The education of the candidates with university, duration, and description of work done like XYZ university from 08-2013 to 07-2018, studied these courses.\"),\n",
    "    ResponseSchema(name=\"awards\", description=\"The awards are the achievements and honors of the candidates. If the resume doesn't have the award, no need to add this to the resume.\"),\n",
    "    ResponseSchema(name=\"projects\", description=\"The projects section contains the project, duration, and roles and responsibilities of the candidate like XYZ project from 05-2019 to 04-2020, worked on the backend, etc.\"),\n",
    "    ResponseSchema(name=\"skills\", description=\"An itemized list of technical skills and non-technical soft skills of the user.\"),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04a4ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You're a skilled Resume Writer with a talent for providing resume from the list of suggestions with no extra information. Your process is precise and methodically follows the given steps and provide a resume with this format {format_instructions}\\n {resume} \\n{Improvements}\",\n",
    "    input_variables=['resume','Improvements'],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b5a797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "# Prompt includes\n",
    "# - Steps for LLM to follow\n",
    "# - Separator tokens, like <> and backticks for delineating steps and inputs\n",
    "\n",
    "prompt_msgs = [\n",
    "    system_message_prompt,\n",
    "    HumanMessage(\n",
    "        content=(\n",
    "            \"Your objective is to thoroughly analyze both a improvements and my resume, pinpoint the requirements outlined in the job posting that are absent in my resume, and form a resume with the format\" \n",
    "        )\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=(\n",
    "            \"\\nSteps to follow:\"\n",
    "            \"\\nStep 1: Get the Resume for the editing from system_message\"\n",
    "            \"\\nStep 2: Get the Suggested Improvements for the editing from system_message\"\n",
    "            \"\\nStep 3: You must create an resume with those Suggestions which is from the Suggested Improvements from Step 2 that are NOT present in the Resume from Step 1. Follow these sub-steps:\"\n",
    "            \"\\n   Sub-Step 3a: The Basics information of the resume holder should be same\"\n",
    "            \"\"\"\\n   Sub-Step 3b: To add the resume information, For each missing requirement that you identified in Sub-Step 3a, check again whether that requirement is in fact present in my Resume. \n",
    "            Note that a requirement may be present in the Resume in a different phrasing than in the job posting. If the requirement is present in the Resume, remove it from your list of missing requirements.\"\"\"\n",
    "            \"\\n   Sub-Step 3c: Education, work experience and all the factual data remain the same, enhance the descriptions the most\"\n",
    "            \"\\nStep 4: You must finally create a resume for improving my Resume based on the list of missing requirements provided.\"\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    HumanMessage(\n",
    "        content=\"You must now use all the steps starting till step 3 and include sub steps in the step 3 and form a resume for step 4 using some rules to form resume in format given\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Notes: Make sure to answer in the correct format, and stick to any word or item limits.\"\n",
    "    ),\n",
    "]\n",
    "improver_prompt = ChatPromptTemplate(messages=prompt_msgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdd015ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_imputs = dict(\n",
    "    Improvements = Improvements,\n",
    "    resume = resume\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3c2bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You're a skilled Resume Writer with a talent for providing resume from the list of suggestions with no extra information. Your process is precise and methodically follows the given steps and provide a resume with this format The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"basics\": string  // The basics of the given user's resume input.\n",
      "\t\"introduction\": string  // Write only 1 line introduction for the introduction section for given user resume input.\n",
      "\t\"work_experiences\": string  // The experience of the candidates with job, duration, and description of work done like XYZ company from 09-2022 to 08-2023, performed work on Spark and databases.\n",
      "\t\"education\": string  // The education of the candidates with university, duration, and description of work done like XYZ university from 08-2013 to 07-2018, studied these courses.\n",
      "\t\"awards\": string  // The awards are the achievements and honors of the candidates. If the resume doesn't have the award, no need to add this to the resume.\n",
      "\t\"projects\": string  // The projects section contains the project, duration, and roles and responsibilities of the candidate like XYZ project from 05-2019 to 04-2020, worked on the backend, etc.\n",
      "\t\"skills\": string  // An itemized list of technical skills and non-technical soft skills of the user.\n",
      "}\n",
      "```\n",
      " Charishma Puli cpuli1@umbc.edu | +16677703907 Academic Qualification  ——————————————————————— University of Maryland, Baltimore County     Expected: May 2023  Master of Professional Studies in Data Science, GPA: 3.6/4.0 (Till Date)  Related Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management. Jawaharlal Nehru Technological University Hyderabad   Graduated: May 2021 Bachelors of Technology, Computer Science and Engineering, GPA: 8.02/10 Related Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence. Work Experience ———————————————————————Atoms Lab | Research Assistant (UMBC)      (Aug 2023 to Present) •Working on Symbolic Regression Algorithm in Genetic Programming. • Generating computer generated equations for zeolites atoms combinations with other elements. The goal is to predict polyatomic combination equations with zeolites Wipro Technology Limited | Project Engineer ( Data Analyst )         (Aug 2021 to Aug 2022) •Worked on Informatics ETL tool •Trained on Big Data in Hadoop, Apache Spark, Hive, AWS •Data analyst & information management. Verzeo Internship                (Aug 2020 to Oct 2020) •Created Machine Learning models •Used data visualization for the analysis of student behavior algorithms •Used Machine Learning algorithms like linear regression, random forest for analyzing the heart diseases Projects ——————————————————————— Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning ( Mar 2021 to May 2021)•Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays, Every image is consisted to 224,224 pixels.•Used CNN (Convolutional Neural Networks) model RESNET50, which extract each feature from the image. Every feature is ﬂattened and then classifying withe the DENSE layer as FULLY CONNECTED LAYER with SIGMOID activation done. •ResNet50 is a variant of ResNet model which has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer.\n",
      "•The model gives 92 % accuracy. It is able to precisely identify whether the provided x- ray is of Covid symptomatic or not.IMDB sentimental analysis and recommendation system           (Jan 2020 to Feb 2020)•The model predict the sentiment (Positive and Negative) of the input sentence. The model adds with genre based recommendation system at the end.•The neural network is a sequential model, which is Dense layered network with Relu activation function in hidden layer and Sigmoid activation function for the output layer.Classiﬁcation Model that predicts heart disease in a subject          (Sept 2020 to Oct 2020)•Built a classiﬁcation model that predicts heart disease in a subject•By implementing various frameworks such as Keras, TensorFlow, Scikit- Learn, Gradient boosting and used various techniques such as Logistic Regression, Bayesian model, Neural Networks, Random forest, SVM, Decision Tree, KNN. Exploratory Data Analysis that analyze students performance         (Aug 2020 to Sept 2020)•Analysis on understanding how the student’s performance (test scores) is affected by the other variables (Gender, Ethnicity, Parental level of education, Lunch, Test preparation course). Online bus reservation system          (Dec 2019 to Mar 2020)•Project Link:Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system Technical Skills——————————————————————— Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & AlgorithmsData Visualization tools: Tableau, Power BI Web Designing: HTML , CSS , JavaScript Cloud & Database: Oracle, SQL, Apache Spark, Hadoop Achievements——————————————————————— •Secured second Prize in Competitive Programming Workshop, Organised by Coding Club JNTUH-CEH (2020)  •JNTUH QUEST 2020 - Coordinator for \"BLOCKCHAIN Technology\" Workshop (2020) JNTUH QUEST 2019 - Participated in \"DATA SCIENCE & MACHINE LEARNING” Workshop (2018) Participated in Workshop conducted by JNTUH •TEDX - MLRIT (2019) Participated in TED talks conducted by MLRIT •PATH CREATORS, HYDERABAD (2018) Attended Workshop on ROBOTICS and constructed a real time robot \n",
      "1. Add a summary or objective statement at the beginning of the resume to provide a brief overview of your skills and career goals.\n",
      "2. Include specific achievements and quantifiable results in your work experience section to demonstrate your impact and contributions.\n",
      "3. Use bullet points to highlight your responsibilities and accomplishments in each job or project.\n",
      "4. Organize your projects section by listing them in reverse chronological order, starting with the most recent.\n",
      "5. Provide more details about your projects, including the tools and techniques used, the challenges faced, and the outcomes achieved.\n",
      "6. Expand on your technical skills section by providing more specific information about your proficiency level and any relevant certifications or training.\n",
      "7. Consider adding a section for relevant coursework or academic projects to showcase your knowledge and skills in data science.\n",
      "8. Include any relevant professional affiliations, such as memberships in data science organizations or participation in industry conferences.\n",
      "9. Proofread your resume for any grammatical or spelling errors, and ensure consistent formatting throughout.\n",
      "Human: Your objective is to thoroughly analyze both a improvements and my resume, pinpoint the requirements outlined in the job posting that are absent in my resume, and form a resume with the format\n",
      "Human: \n",
      "Steps to follow:\n",
      "Step 1: Get the Resume for the editing from system_message\n",
      "Step 2: Get the Suggested Improvements for the editing from system_message\n",
      "Step 3: You must create an resume with those Suggestions which is from the Suggested Improvements from Step 2 that are NOT present in the Resume from Step 1. Follow these sub-steps:\n",
      "   Sub-Step 3a: The Basics information of the resume holder should be same\n",
      "   Sub-Step 3b: To add the resume information, For each missing requirement that you identified in Sub-Step 3a, check again whether that requirement is in fact present in my Resume. \n",
      "            Note that a requirement may be present in the Resume in a different phrasing than in the job posting. If the requirement is present in the Resume, remove it from your list of missing requirements.\n",
      "   Sub-Step 3c: Education, work experience and all the factual data remain the same, enhance the descriptions the most\n",
      "Step 4: You must finally create a resume for improving my Resume based on the list of missing requirements provided.\n",
      "Human: You must now use all the steps starting till step 3 and include sub steps in the step 3 and form a resume for step 4 using some rules to form resume in format given\n",
      "Human: Notes: Make sure to answer in the correct format, and stick to any word or item limits.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "better_improver_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=improver_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "better_improver_chain_response = better_improver_chain.predict(**prompt_imputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3448f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"basics\": \"Charishma Puli cpuli1@umbc.edu | +16677703907\",\n",
      "\t\"introduction\": \"Data Science professional with a strong background in computer science and engineering, seeking opportunities to apply my skills and contribute to impactful projects.\",\n",
      "\t\"work_experiences\": \"Atoms Lab | Research Assistant (UMBC) (Aug 2023 to Present)\\n• Working on Symbolic Regression Algorithm in Genetic Programming.\\n• Generating computer-generated equations for zeolite atom combinations with other elements.\\n\\nWipro Technology Limited | Project Engineer (Data Analyst) (Aug 2021 to Aug 2022)\\n• Worked on Informatics ETL tool.\\n• Trained on Big Data in Hadoop, Apache Spark, Hive, AWS.\\n\\nVerzeo Internship (Aug 2020 to Oct 2020)\\n• Created Machine Learning models.\\n• Used data visualization for the analysis of student behavior algorithms.\\n• Used Machine Learning algorithms like linear regression, random forest for analyzing heart diseases.\",\n",
      "\t\"education\": \"University of Maryland, Baltimore County | Expected: May 2023\\nMaster of Professional Studies in Data Science, GPA: 3.6/4.0\\nRelated Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management.\\n\\nJawaharlal Nehru Technological University Hyderabad | Graduated: May 2021\\nBachelors of Technology, Computer Science and Engineering, GPA: 8.02/10\\nRelated Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence.\",\n",
      "\t\"awards\": \"\",\n",
      "\t\"projects\": \"Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning (Mar 2021 to May 2021)\\n• Built a Deep Learning model by implementing Convolutional Neural Network that predicts COVID-19 with chest X-rays.\\n\\nIMDB sentimental analysis and recommendation system (Jan 2020 to Feb 2020)\\n• The model predicts the sentiment (Positive and Negative) of the input sentence.\\n\\nClassiﬁcation Model that predicts heart disease in a subject (Sept 2020 to Oct 2020)\\n• Built a classiﬁcation model that predicts heart disease in a subject.\\n\\nExploratory Data Analysis that analyzes students' performance (Aug 2020 to Sept 2020)\\n• Analysis on understanding how the student’s performance (test scores) is affected by other variables.\\n\\nOnline bus reservation system (Dec 2019 to Mar 2020)\\n• Project Link: Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system\",\n",
      "\t\"skills\": \"Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & Algorithms\\nData Visualization tools: Tableau, Power BI\\nWeb Designing: HTML, CSS, JavaScript\\nCloud & Database: Oracle, SQL, Apache Spark, Hadoop\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(better_improver_chain_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5e842df",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_improver_chain_response = better_improver_chain_response.replace('```json\\n','')\n",
    "Pred_COT_self_Imporving = better_improver_chain_response.replace('\\n```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "185a5485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\\t\"basics\": \"Charishma Puli cpuli1@umbc.edu | +16677703907\",\\n\\t\"introduction\": \"Data Science professional with a strong background in computer science and engineering, seeking opportunities to apply my skills and contribute to impactful projects.\",\\n\\t\"work_experiences\": \"Atoms Lab | Research Assistant (UMBC) (Aug 2023 to Present)\\\\n• Working on Symbolic Regression Algorithm in Genetic Programming.\\\\n• Generating computer-generated equations for zeolite atom combinations with other elements.\\\\n\\\\nWipro Technology Limited | Project Engineer (Data Analyst) (Aug 2021 to Aug 2022)\\\\n• Worked on Informatics ETL tool.\\\\n• Trained on Big Data in Hadoop, Apache Spark, Hive, AWS.\\\\n\\\\nVerzeo Internship (Aug 2020 to Oct 2020)\\\\n• Created Machine Learning models.\\\\n• Used data visualization for the analysis of student behavior algorithms.\\\\n• Used Machine Learning algorithms like linear regression, random forest for analyzing heart diseases.\",\\n\\t\"education\": \"University of Maryland, Baltimore County | Expected: May 2023\\\\nMaster of Professional Studies in Data Science, GPA: 3.6/4.0\\\\nRelated Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management.\\\\n\\\\nJawaharlal Nehru Technological University Hyderabad | Graduated: May 2021\\\\nBachelors of Technology, Computer Science and Engineering, GPA: 8.02/10\\\\nRelated Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence.\",\\n\\t\"awards\": \"\",\\n\\t\"projects\": \"Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning (Mar 2021 to May 2021)\\\\n• Built a Deep Learning model by implementing Convolutional Neural Network that predicts COVID-19 with chest X-rays.\\\\n\\\\nIMDB sentimental analysis and recommendation system (Jan 2020 to Feb 2020)\\\\n• The model predicts the sentiment (Positive and Negative) of the input sentence.\\\\n\\\\nClassiﬁcation Model that predicts heart disease in a subject (Sept 2020 to Oct 2020)\\\\n• Built a classiﬁcation model that predicts heart disease in a subject.\\\\n\\\\nExploratory Data Analysis that analyzes students\\' performance (Aug 2020 to Sept 2020)\\\\n• Analysis on understanding how the student’s performance (test scores) is affected by other variables.\\\\n\\\\nOnline bus reservation system (Dec 2019 to Mar 2020)\\\\n• Project Link: Charishma_Puli https://github.com/charishma13/Online_bus_reserva- tion_system\",\\n\\t\"skills\": \"Programming Languages: C, Java, Python, R, JDBC, Machine Learning, Data Structure & Algorithms\\\\nData Visualization tools: Tableau, Power BI\\\\nWeb Designing: HTML, CSS, JavaScript\\\\nCloud & Database: Oracle, SQL, Apache Spark, Hadoop\"\\n}'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_COT_self_Imporving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e1bbe",
   "metadata": {},
   "source": [
    "Model has done considerable well, by retaining and making advancements to the important aspects of the resume based on the job description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040dff6",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebdc087",
   "metadata": {},
   "source": [
    "### Sari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b72e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/spaces/evaluate-metric/sari\n",
    "\n",
    "from evaluate import load\n",
    "sari = load(\"sari\")\n",
    "sources=[resume]\n",
    "predictions=[Pred_COT_self_Imporving]\n",
    "references=[[job_posting]]\n",
    "sari_score = sari.compute(sources=sources, predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef43b3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sari': 35.62325484516239}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sari_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bd2a0",
   "metadata": {},
   "source": [
    "### hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cd10e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "hallucination_model = CrossEncoder('vectara/hallucination_evaluation_model')\n",
    "score = hallucination_model.predict([\n",
    "    [resume, Pred_COT_self_Imporving],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19246a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85426855], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f535e2c",
   "metadata": {},
   "source": [
    "Adding evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23004c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Scores['Chain_Of_Thoughts_SeLF_Improving'] = [sari_score['sari'],score[0]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e92deb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero_Shot_Prompting</th>\n",
       "      <th>Chain_Of_Thoughts_Step_by_Step</th>\n",
       "      <th>Chain_Of_Thoughts_SeLF_Improving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sari</th>\n",
       "      <td>34.924085</td>\n",
       "      <td>35.624134</td>\n",
       "      <td>35.623255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucination</th>\n",
       "      <td>51.236480</td>\n",
       "      <td>86.174220</td>\n",
       "      <td>85.426855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Zero_Shot_Prompting  Chain_Of_Thoughts_Step_by_Step  \\\n",
       "Sari                     34.924085                       35.624134   \n",
       "hallucination            51.236480                       86.174220   \n",
       "\n",
       "               Chain_Of_Thoughts_SeLF_Improving  \n",
       "Sari                                  35.623255  \n",
       "hallucination                         85.426855  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679db573",
   "metadata": {},
   "source": [
    "## Instructions Prompting\n",
    "\n",
    "ref: https://medium.com/@SymeCloud/a-brief-understanding-of-prompt-engineering-b176ba9fb2ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7ff086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "055ee428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\" {query} with the job_posting using this latex template {format_instructions}. Don't change actual meaning of the education and work experiecnes and don't add any fake information\",  \n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "human_template = (\"You are going to write a resume section for an applicant applying for job posts, add description for the relavent experiences\"\n",
    "                                \"Consider the following CV structure: {cv_text}\"\n",
    "            \"Consider the following job post improvements: {job_post}\"\n",
    "            \"basics: Extract the name and contant information of the user\"\n",
    "            \"Introduction: Write only a 2-line introduction for the basics section according to the basic schema for the given user resume, don't include users name.\"\n",
    "            \"Education: Write the education section according to the Education schema. On the response.\"\n",
    "            \"Awards: Write the awards section according to the Awards schema. Include only the awards section. On the response.\"\n",
    "            \"Work: Write a work section for the candidate according to the Work schema. Include only the work experience and not the project experience. For each work experience, provide a company name, position name, start and end date, and bullet point for the highlights. Follow the Harvard Extension School Resume guidelines and phrase the highlights with the STAR methodology.\"\n",
    "            \"Skills: Write the skills section according to the Skills schema. Include only up to the top 4 skill names that are present in the CV and related to the education and work experience. On the response.\"\n",
    "            \"Projects: Write the projects section according to the Projects schema. Include all projects, but only the ones present in the CV. On the response.\"\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51771d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68ca4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_imputs = dict(\n",
    "    cv_text = resume,\n",
    "    job_post = Improvements,\n",
    "    query = 'Enhance the given cv of the user for better job oppertunities.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42b8533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_with_values = chat_prompt.format_prompt(**prompt_imputs)\n",
    "\n",
    "## chat_prompt_with_values.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20604676",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model(chat_prompt_with_values.to_messages()).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f5d914d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"basics\": \"Charishma Puli\\nEmail: cpuli1@umbc.edu\\nPhone: +16677703907\",\n",
      "\t\"introduction\": \"Data science professional with a strong background in computer science and engineering.\",\n",
      "\t\"work_experiences\": \"Atoms Lab | Research Assistant (UMBC) | Aug 2023 - Present\\n- Working on Symbolic Regression Algorithm in Genetic Programming\\n- Generating computer-generated equations for zeolite atoms combinations with other elements\\n\\nWipro Technology Limited | Project Engineer (Data Analyst) | Aug 2021 - Aug 2022\\n- Worked on Informatics ETL tool\\n- Trained on Big Data in Hadoop, Apache Spark, Hive, AWS\\n- Data analyst & information management\\n\\nVerzeo Internship | Aug 2020 - Oct 2020\\n- Created Machine Learning models\\n- Used data visualization for the analysis of student behavior algorithms\\n- Used Machine Learning algorithms like linear regression, random forest for analyzing heart diseases\",\n",
      "\t\"education\": \"University of Maryland, Baltimore County | Expected: May 2023\\nMaster of Professional Studies in Data Science, GPA: 3.6/4.0\\nRelated Coursework: Introduction to Data Science, Data Management, Machine Learning, Big Data, Large Language Models, Financial Data Science, Leadership in Management\\n\\nJawaharlal Nehru Technological University Hyderabad | Graduated: May 2021\\nBachelors of Technology, Computer Science and Engineering, GPA: 8.02/10\\nRelated Coursework: C, Data Structures and Algorithms, Statistics & Probability, Operating Systems, Compiler Design, Computer Networks, Cloud Computing, Database management systems, Machine Learning, Artificial Intelligence\",\n",
      "\t\"awards\": \"- Secured second Prize in Competitive Programming Workshop, Organised by Coding Club JNTUH-CEH (2020)\\n- JNTUH QUEST 2020 - Coordinator for 'BLOCKCHAIN Technology' Workshop (2020)\\n- JNTUH QUEST 2019 - Participated in 'DATA SCIENCE & MACHINE LEARNING' Workshop (2018)\\n- Participated in Workshop conducted by JNTUH\\n- TEDX - MLRIT (2019) Participated in TED talks conducted by MLRIT\\n- PATH CREATORS, HYDERABAD (2018) Attended Workshop on ROBOTICS and constructed a real-time robot\",\n",
      "\t\"projects\": \"- Prediction Of Covid-19 Certainty from X-Ray Images Using Deep Learning (Mar 2021 - May 2021)\\n  - Built a Deep Learning model by implementing Convolutional Neural Network that predicts covid-19 with chest X-rays\\n  - Used CNN (Convolutional Neural Networks) model RESNET50\\n  - The model gives 92% accuracy\\n\\n- IMDB sentimental analysis and recommendation system (Jan 2020 - Feb 2020)\\n  - The model predicts the sentiment (Positive and Negative) of the input sentence\\n  - The neural network is a sequential model\\n\\n- Classification Model that predicts heart disease in a subject (Sept 2020 - Oct 2020)\\n  - Built a classification model that predicts heart disease in a subject\\n  - Implemented various frameworks such as Keras, TensorFlow, Scikit-Learn, Gradient boosting\\n\\n- Exploratory Data Analysis that analyzes students' performance (Aug 2020 - Sept 2020)\\n  - Analysis on understanding how the student's performance (test scores) is affected by other variables\\n\\n- Online bus reservation system (Dec 2019 - Mar 2020)\\n  - Project Link: Charishma_Puli https://github.com/charishma13/Online_bus_reservation_system\",\n",
      "\t\"skills\": \"- Programming Languages: C, Java, Python, R\\n- Data Visualization tools: Tableau, Power BI\\n- Web Designing: HTML, CSS, JavaScript\\n- Cloud & Database: Oracle, SQL, Apache Spark, Hadoop\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb3a00",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "227c8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/spaces/evaluate-metric/sari\n",
    "\n",
    "from evaluate import load\n",
    "sari = load(\"sari\")\n",
    "sources=[resume]\n",
    "predictions=[response]\n",
    "references=[[job_posting]]\n",
    "sari_score = sari.compute(sources=sources, predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7735b5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sari': 34.988602605288555}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sari_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1eaf2",
   "metadata": {},
   "source": [
    "### hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "16127292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "hallucination_model = CrossEncoder('vectara/hallucination_evaluation_model')\n",
    "score = hallucination_model.predict([\n",
    "    [resume, response],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d39223c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88758385], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac24f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Scores['Instruction_Prompting'] = [sari_score['sari'],score[0]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53db1d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero_Shot_Prompting</th>\n",
       "      <th>Chain_Of_Thoughts_Step_by_Step</th>\n",
       "      <th>Chain_Of_Thoughts_SeLF_Improving</th>\n",
       "      <th>Instruction_Prompting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sari</th>\n",
       "      <td>34.924085</td>\n",
       "      <td>35.624134</td>\n",
       "      <td>35.623255</td>\n",
       "      <td>34.988603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucination</th>\n",
       "      <td>51.236480</td>\n",
       "      <td>86.174220</td>\n",
       "      <td>85.426855</td>\n",
       "      <td>88.758385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Zero_Shot_Prompting  Chain_Of_Thoughts_Step_by_Step  \\\n",
       "Sari                     34.924085                       35.624134   \n",
       "hallucination            51.236480                       86.174220   \n",
       "\n",
       "               Chain_Of_Thoughts_SeLF_Improving  Instruction_Prompting  \n",
       "Sari                                  35.623255              34.988603  \n",
       "hallucination                         85.426855              88.758385  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f9462e",
   "metadata": {},
   "source": [
    "## Evaluation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14d73967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero_Shot_Prompting</th>\n",
       "      <th>Chain_Of_Thoughts_Step_by_Step</th>\n",
       "      <th>Chain_Of_Thoughts_SeLF_Improving</th>\n",
       "      <th>Instruction_Prompting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sari</th>\n",
       "      <td>34.924085</td>\n",
       "      <td>35.624134</td>\n",
       "      <td>35.623255</td>\n",
       "      <td>34.988603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucination</th>\n",
       "      <td>51.236480</td>\n",
       "      <td>86.174220</td>\n",
       "      <td>85.426855</td>\n",
       "      <td>88.758385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Zero_Shot_Prompting  Chain_Of_Thoughts_Step_by_Step  \\\n",
       "Sari                     34.924085                       35.624134   \n",
       "hallucination            51.236480                       86.174220   \n",
       "\n",
       "               Chain_Of_Thoughts_SeLF_Improving  Instruction_Prompting  \n",
       "Sari                                  35.623255              34.988603  \n",
       "hallucination                         85.426855              88.758385  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e64814",
   "metadata": {},
   "source": [
    "## Better Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b6032",
   "metadata": {},
   "source": [
    "Instruction_Prompting and Chain_Of_Thoughts_Step_by_Step both performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad8e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
